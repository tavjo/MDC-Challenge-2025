# Make Data Count - Finding Data References Challenge 2025

A comprehensive solution for identifying and classifying data citations in scientific literature using advanced NLP techniques.

## ğŸ¯ Challenge Overview

This project addresses the **Make Data Count - Finding Data References** Kaggle Challenge, which aims to identify all data citations from scientific literature and classify them by citation type:

- **Primary**: Raw or processed data generated as part of the paper, specifically for the study
- **Secondary**: Raw or processed data derived or reused from existing records or published data

The [challenge](CHALLENGE_OVERVIEW.md) involves processing scientific papers from the Europe PMC open access subset, available in both PDF and XML formats, to extract research data references and classify them accurately.

## ğŸ“ Project Structure

```
MDC-Challenge-2025/
â”œâ”€â”€ Data/                               # Dataset and generated workflow files
â”‚   â”œâ”€â”€ train_labels.csv               # Training labels
â”‚   â”œâ”€â”€ train/                         # Training documents
â”‚   â”‚   â”œâ”€â”€ PDF/                       # PDF files (524 files)
â”‚   â”‚   â””â”€â”€ XML/                       # XML files (400 files, ~75% coverage)
â”‚   â”œâ”€â”€ test/                          # Test documents
â”‚   â”‚   â”œâ”€â”€ PDF/                       # Test PDF files
â”‚   â”‚   â””â”€â”€ XML/                       # Test XML files
â”‚   â”œâ”€â”€ conversion_candidates.csv      # Generated: Articles needing PDFâ†’XML conversion
â”‚   â”œâ”€â”€ document_inventory.csv         # Generated: Complete document inventory
â”‚   â””â”€â”€ problematic_articles.txt       # Generated: Articles missing both formats
â”œâ”€â”€ src/                               # Core modules
â”‚   â”œâ”€â”€ label_mapper.py                # Label analysis and document mapping
â”‚   â”œâ”€â”€ document_parser.py             # Document parsing and extraction
â”‚   â”œâ”€â”€ semantic_chunking.py           # Text chunking for processing
â”‚   â”œâ”€â”€ pdf_to_xml_conversion.py       # PDF to XML conversion utilities
â”‚   â”œâ”€â”€ xml_format_detector.py         # XML format detection and validation
â”‚   â”œâ”€â”€ section_mapping.py             # Document section mapping
â”‚   â”œâ”€â”€ helpers.py                     # Utility functions and logging
â”‚   â””â”€â”€ models.py                      # Data models and schemas
â”œâ”€â”€ scripts/                           # Executable scripts
â”‚   â”œâ”€â”€ run_prechunking_eda.py         # Pre-chunking exploratory data analysis
â”‚   â”œâ”€â”€ run_full_doc_parsing.py        # Full document parsing pipeline
â”‚   â”œâ”€â”€ run_chunking_pipeline.py       # Semantic chunking pipeline
â”‚   â”œâ”€â”€ run_doc_conversion.py          # PDFâ†’XML conversion script
â”‚   â””â”€â”€ demo_prechunking_eda.py        # EDA demonstration script
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â””â”€â”€ label_doc_mapping.ipynb        # Label and document mapping analysis
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ prechunking_eda_script_guide.md # EDA script usage guide
â”‚   â””â”€â”€ pdf_to_xml_guide.md            # PDF to XML conversion guide
â”œâ”€â”€ reports/                           # Generated analysis reports
â”‚   â”œâ”€â”€ prechunking_eda_report_*.md    # EDA analysis reports
â”‚   â””â”€â”€ prechunking_eda_summary_*.json # EDA summary data
â”œâ”€â”€ models/                            # Trained models and artifacts
â”œâ”€â”€ tests/                             # Test files
â”œâ”€â”€ logs/                              # Application logs
â”œâ”€â”€ guides/                            # Additional guides and documentation
â”œâ”€â”€ main.py                            # Main entry point
â”œâ”€â”€ preprocessing.py                   # Preprocessing pipeline coordinator
â”œâ”€â”€ pyproject.toml                     # Project configuration and dependencies
â””â”€â”€ README.md                          # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.12+
- UV package manager (recommended) or pip

### Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/MDC-Challenge-2025.git
cd MDC-Challenge-2025
```

2. Install dependencies:
```bash
# Using UV (recommended)
uv sync

# Or using pip
pip install -e .
```

### Quick Start

1. **Run Pre-chunking EDA**:
```bash
python scripts/run_prechunking_eda.py --data-dir Data
```

## ğŸ”§ Core Components

### Data Analysis (`src/label_mapper.py`)
- Comprehensive label and document analysis
- PDFâ†”XML file mapping and availability tracking
- Quality checks and validation
- Conversion workflow planning

### Document Processing (`src/document_parser.py`)
- Multi-format document parsing (PDF, XML)
- Text extraction and preprocessing
- Section identification and mapping
- Metadata extraction

### Semantic Chunking (`src/semantic_chunking.py`)
- Intelligent text segmentation
- Context-aware chunking strategies
- Optimized for citation detection
- Configurable chunk sizes and overlap

### PDF to XML Conversion (`src/pdf_to_xml_conversion.py`)
- Automated PDF to XML conversion
- Format validation and quality checks
- Batch processing capabilities
- Error handling and logging

## ğŸ“Š Analysis and Reporting

The project includes comprehensive analysis tools:

- **Pre-chunking EDA**: Detailed analysis of labels and document availability
- **Document Inventory**: Complete mapping of available files
- **Conversion Workflow**: Automated PDFâ†’XML conversion planning
- **Quality Checks**: Data validation and consistency checks
- **Progress Tracking**: Detailed logging and reporting

## ğŸ† Challenge Details

- **Competition**: Make Data Count - Finding Data References
- **Platform**: Kaggle
- **Evaluation Metric**: F1-Score
- **Dataset**: Europe PMC open access subset
- **Timeline**: June 11, 2025 - September 9, 2025
- **Total Prize Pool**: $100,000

## ğŸ‘¥ Contributors

- [**Douaa Mugahid**](https://www.linkedin.com/in/doaa-megahed-185150100/) - Lead
- [**Elliott Risch**](https://www.linkedin.com/in/modusponens/) - Solutions Architect
- [**TaÃ¯sha Joseph-Risch**](http://www.linkedin.com/in/taÃ¯sha-joseph-0974229b) - ML Specialist (taishajo@mit.edu)

## ğŸ“ˆ Development Workflow

1. **Data Analysis**: Run EDA scripts to understand dataset characteristics
2. **Document Processing**: Convert PDFs to XML where needed
3. **Text Extraction**: Parse documents and extract relevant sections
4. **Chunking**: Apply semantic chunking for optimal processing
5. **Feature Engineering**: Extract features relevant to citation detection
6. **Model Training**: Train models for citation identification and classification
7. **Evaluation**: Validate model performance using F1-score
8. **Deployment**: Prepare final submission

## ğŸ” Key Features

- **Multi-format Support**: Handles both PDF and XML documents
- **Intelligent Preprocessing**: Automated workflow planning and execution
- **Comprehensive Analysis**: Detailed EDA and quality assessment
- **Scalable Processing**: Efficient batch processing capabilities
- **Robust Logging**: Detailed progress tracking and error handling
- **Flexible Configuration**: Configurable parameters for different use cases

## ğŸ“š Documentation

- [Pre-chunking EDA Guide](docs/prechunking_eda_script_guide.md)
- [PDF to XML Conversion Guide](docs/pdf_to_xml_guide.md)
- [Label Document Mapping Notebook](notebooks/label_doc_mapping.ipynb)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Make Data Count initiative and DataCite for organizing the challenge
- The Navigation Fund and Chan Zuckerberg Initiative for sponsoring the prizes
- Europe PMC for providing the open access corpus
- The scientific community for their valuable research contributions

---

*Competition sponsored by DataCite International Data Citation Initiative e.V, with prize funds from The Navigation Fund and Chan Zuckerberg Initiative.*