services:
  mdc-challenge:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mdc-challenge-2025
    environment:
      - PYTHONPATH=/app
      - UV_CACHE_DIR=/tmp/uv-cache
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      # Mount data directory for persistence
      - ./Data:/app/Data
      - ./src:/app/src
      - ./artifacts:/app/artifacts
      - ./tests:/app/tests
      - ./configs:/app/configs
      - ./api:/app/api
    working_dir: /app
    ports:
      - "3000:3000"
    # Use consistent command with Dockerfile (remove "uv run")
    command: ["uvicorn", "api.parse_doc_api:app", "--host", "0.0.0.0", "--port", "3000"]

  # # Optional: Development service with interactive shell
  mdc-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mdc-challenge-dev
    environment:
      - PYTHONPATH=/app
      # - UV_CACHE_DIR=/tmp/uv-cache
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      # Mount entire project for development
      - ./:/app
      - uv-cache:/tmp/uv-cache
    working_dir: /app
    command: ["tail", "-f", "/dev/null"]  # Keep container running
    profiles:
      - dev

  # API service for chunking and embedding microservice
  # mdc-api:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.api
  #   container_name: mdc-challenge-api
  #   environment:
  #     - PYTHONPATH=/app
  #     - UV_CACHE_DIR=/tmp/uv-cache
  #     - OPENAI_API_KEY=${OPENAI_API_KEY}
  #     - GEMINI_API_KEY=${GEMINI_API_KEY}
  #   volumes:
  #     # Mount data and artifacts for persistence
  #     - ./artifacts:/app/artifacts
  #     - ./configs:/app/configs
  #     - ./src:/app/src
  #     - ./api:/app/api
  #   working_dir: /app
  #   ports:
  #     - "8000:8000"
  #   command: ["uvicorn", "api.chunk_and_embed_api:app", "--host", "0.0.0.0", "--port", "8000"]
  #   profiles:
  #     - api

volumes:
  uv-cache: