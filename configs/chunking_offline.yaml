# conf/chunking_offline.yaml
# Configuration for offline semantic chunking with SentenceTransformers
splitter: semantic          # switch from "sliding" to "semantic"
max_tokens: 300             # hard ceiling to prevent jumbo chunks
similarity_threshold: 0.75  # cosine drop that triggers a new chunk
min_tokens: 80              # merge stragglers below this size
overlap_sentences: 2        # no duplicated text â†’ lower token bill

# Offline embedding model configuration
# Use offline model by default - no OpenAI API required
embed_model: bge-small-en-v1.5

# Offline model configuration
offline_model:
  # Default offline model for when OpenAI is not available
  default_model: bge-small-en-v1.5
  # Cache directory for offline models
  cache_dir: ./offline_models
  # Whether to download model if not cached
  auto_download: true

vector_store:
  type: chroma
  path: ./local_chroma 