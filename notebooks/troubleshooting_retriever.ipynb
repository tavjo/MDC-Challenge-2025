{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91a1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025\n",
      "Working from: /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Troubleshooting Retrieval Issues\n",
    "# Checking for stale chunks in DuckDB and ChromaDB\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path \n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working from: {Path.cwd()}\")\n",
    "\n",
    "# Expected chunk count from latest successful run\n",
    "EXPECTED_CHUNKS = 4165  # From chunks_for_embedding_summary.csv (4167 lines - 1 header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae016ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:36:45,134 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/duckdb_utils.log\n",
      "2025-08-01 10:36:45,134 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/duckdb_utils.log\n",
      "2025-08-01 10:36:45,198 - src.helpers - INFO - Database schema initialized successfully\n",
      "2025-08-01 10:36:45,198 - src.helpers - INFO - Database schema initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECKING DUCKDB ===\n",
      "📊 Database Statistics:\n",
      "  total_documents: 524\n",
      "  total_citations: 487\n",
      "  total_chunks: 4205\n",
      "  documents_with_citations: 0\n",
      "\n",
      "🔍 Expected chunks: 4165\n",
      "🔍 Actual chunks in DuckDB: 4205\n",
      "⚠️  DuckDB has 40 extra chunks (stale data)\n"
     ]
    }
   ],
   "source": [
    "# Check DuckDB chunk count\n",
    "from api.utils.duckdb_utils import get_duckdb_helper\n",
    "\n",
    "print(\"=== CHECKING DUCKDB ===\")\n",
    "db_helper = get_duckdb_helper(str(project_root / \"artifacts\" / \"mdc_challenge.db\"))\n",
    "\n",
    "# Get database statistics\n",
    "stats = db_helper.get_database_stats()\n",
    "print(f\"📊 Database Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "actual_chunks_db = stats['total_chunks']\n",
    "print(f\"\\n🔍 Expected chunks: {EXPECTED_CHUNKS}\")\n",
    "print(f\"🔍 Actual chunks in DuckDB: {actual_chunks_db}\")\n",
    "\n",
    "if actual_chunks_db == EXPECTED_CHUNKS:\n",
    "    print(\"✅ DuckDB chunk count matches expected!\")\n",
    "elif actual_chunks_db > EXPECTED_CHUNKS:\n",
    "    print(f\"⚠️  DuckDB has {actual_chunks_db - EXPECTED_CHUNKS} extra chunks (stale data)\")\n",
    "else:\n",
    "    print(f\"❌ DuckDB is missing {EXPECTED_CHUNKS - actual_chunks_db} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d903b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHECKING CHROMADB ===\n",
      "ChromaDB path: /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/local_chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:36:47,119 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-08-01 10:36:47,119 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Found 1 collections:\n",
      "  📂 mdc_training_data: 4165 chunks\n",
      "\n",
      "🔍 Expected chunks: 4165\n",
      "🔍 Total chunks in ChromaDB: 4165\n",
      "✅ ChromaDB chunk count matches expected!\n"
     ]
    }
   ],
   "source": [
    "# Check ChromaDB chunk count\n",
    "import chromadb\n",
    "import yaml\n",
    "\n",
    "print(\"\\n=== CHECKING CHROMADB ===\")\n",
    "\n",
    "# Load config to get ChromaDB path\n",
    "config_path = project_root / \"configs\" / \"chunking.yaml\"\n",
    "with open(config_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "chroma_path = project_root / cfg[\"vector_store\"].get(\"path\", \"./local_chroma\")\n",
    "print(f\"ChromaDB path: {chroma_path}\")\n",
    "\n",
    "# Connect to ChromaDB\n",
    "client = chromadb.PersistentClient(path=str(chroma_path))\n",
    "\n",
    "# List all collections\n",
    "collections = client.list_collections()\n",
    "print(f\"📁 Found {len(collections)} collections:\")\n",
    "\n",
    "total_chunks_chroma = 0\n",
    "collection_details = []\n",
    "\n",
    "for collection in collections:\n",
    "    count = collection.count()\n",
    "    total_chunks_chroma += count\n",
    "    collection_details.append((collection.name, count))\n",
    "    print(f\"  📂 {collection.name}: {count} chunks\")\n",
    "\n",
    "print(f\"\\n🔍 Expected chunks: {EXPECTED_CHUNKS}\")\n",
    "print(f\"🔍 Total chunks in ChromaDB: {total_chunks_chroma}\")\n",
    "\n",
    "if total_chunks_chroma == EXPECTED_CHUNKS:\n",
    "    print(\"✅ ChromaDB chunk count matches expected!\")\n",
    "elif total_chunks_chroma > EXPECTED_CHUNKS:\n",
    "    print(f\"⚠️  ChromaDB has {total_chunks_chroma - EXPECTED_CHUNKS} extra chunks (stale data)\")\n",
    "else:\n",
    "    print(f\"❌ ChromaDB is missing {EXPECTED_CHUNKS - total_chunks_chroma} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfc3b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "Expected chunks from latest successful run: 4165\n",
      "DuckDB chunks: 4205\n",
      "ChromaDB chunks: 4165\n",
      "\n",
      "🔍 STALE DATA DETECTED:\n",
      "  - DuckDB has 40 stale chunks\n",
      "\n",
      "💡 This explains the retrieval failures:\n",
      "  - ChromaDB returns stale chunk IDs during similarity search\n",
      "  - DuckDB lookup fails for these stale IDs\n",
      "  - Result: 0 chunks retrieved → marked as unsuccessful\n"
     ]
    }
   ],
   "source": [
    "# Summary and next steps\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Expected chunks from latest successful run: {EXPECTED_CHUNKS}\")\n",
    "print(f\"DuckDB chunks: {actual_chunks_db}\")\n",
    "print(f\"ChromaDB chunks: {total_chunks_chroma}\")\n",
    "\n",
    "# Check for inconsistencies\n",
    "duckdb_extra = actual_chunks_db - EXPECTED_CHUNKS if actual_chunks_db > EXPECTED_CHUNKS else 0\n",
    "chromadb_extra = total_chunks_chroma - EXPECTED_CHUNKS if total_chunks_chroma > EXPECTED_CHUNKS else 0\n",
    "\n",
    "if duckdb_extra > 0 or chromadb_extra > 0:\n",
    "    print(\"\\n🔍 STALE DATA DETECTED:\")\n",
    "    if duckdb_extra > 0:\n",
    "        print(f\"  - DuckDB has {duckdb_extra} stale chunks\")\n",
    "    if chromadb_extra > 0:\n",
    "        print(f\"  - ChromaDB has {chromadb_extra} stale chunks\")\n",
    "    \n",
    "    print(\"\\n💡 This explains the retrieval failures:\")\n",
    "    print(\"  - ChromaDB returns stale chunk IDs during similarity search\")\n",
    "    print(\"  - DuckDB lookup fails for these stale IDs\") \n",
    "    print(\"  - Result: 0 chunks retrieved → marked as unsuccessful\")\n",
    "    \n",
    "    if chromadb_extra > 0:\n",
    "        print(f\"\\n📊 ChromaDB Collection Details:\")\n",
    "        for name, count in collection_details:\n",
    "            print(f\"  📂 {name}: {count} chunks\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\n✅ No stale data detected!\")\n",
    "    print(\"💭 The 12 retrieval failures might be due to:\")\n",
    "    print(\"  - Citation pattern matching issues\")  \n",
    "    print(\"  - Citations not found in any chunks\")\n",
    "    print(\"  - Other query construction problems\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de00b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:36:47,297 - src.helpers - INFO - Retrieved 487 citation entities from database\n",
      "2025-08-01 10:36:47,297 - src.helpers - INFO - Retrieved 487 citation entities from database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYZING CITATION PATTERN MATCHING ===\n",
      "📊 Total citations in database: 487\n",
      "📊 Processing 4205 chunks to find assigned citations...\n",
      "📊 Citations found in chunks: 487\n",
      "📊 Missing citations: 0\n",
      "🔍 Expected missing: 49\n",
      "🔍 Actual missing: 0\n",
      "✅ No missing citations found!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PART 2: CITATION PATTERN MATCHING ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=== ANALYZING CITATION PATTERN MATCHING ===\")\n",
    "\n",
    "# Get all citations from the citations table\n",
    "all_citations = db_helper.get_all_citation_entities()\n",
    "print(f\"📊 Total citations in database: {len(all_citations)}\")\n",
    "\n",
    "# Get all citations that are actually assigned to chunks\n",
    "citations_in_chunks = set()\n",
    "all_chunks = []\n",
    "\n",
    "# Query all chunks to collect citation entities\n",
    "result = db_helper.engine.execute(\"SELECT chunk_id, document_id, chunk_metadata FROM chunks\")\n",
    "chunk_rows = result.fetchall()\n",
    "col_names = [desc[0] for desc in result.description]\n",
    "\n",
    "print(f\"📊 Processing {len(chunk_rows)} chunks to find assigned citations...\")\n",
    "\n",
    "for row in chunk_rows:\n",
    "    row_dict = dict(zip(col_names, row))\n",
    "    chunk_metadata = row_dict[\"chunk_metadata\"]\n",
    "    \n",
    "    if chunk_metadata and \"citation_entities\" in chunk_metadata:\n",
    "        citation_strings = chunk_metadata[\"citation_entities\"]\n",
    "        if citation_strings:  # Check if not empty list\n",
    "            for ce_str in citation_strings:\n",
    "                if ce_str:  # Check if not empty string\n",
    "                    # Extract just the data_citation part (first part before |)\n",
    "                    data_citation = ce_str.split(\"|\")[0] if \"|\" in ce_str else ce_str\n",
    "                    citations_in_chunks.add(data_citation)\n",
    "\n",
    "print(f\"📊 Citations found in chunks: {len(citations_in_chunks)}\")\n",
    "print(f\"📊 Missing citations: {len(all_citations) - len(citations_in_chunks)}\")\n",
    "\n",
    "# Find the missing citations\n",
    "all_citation_ids = {ce.data_citation for ce in all_citations}\n",
    "missing_citations = all_citation_ids - citations_in_chunks\n",
    "\n",
    "print(f\"🔍 Expected missing: 49\")\n",
    "print(f\"🔍 Actual missing: {len(missing_citations)}\")\n",
    "\n",
    "if len(missing_citations) > 0:\n",
    "    print(f\"\\n📋 First 10 missing citations:\")\n",
    "    for i, citation in enumerate(list(missing_citations)[:10]):\n",
    "        print(f\"  {i+1}. {citation}\")\n",
    "else:\n",
    "    print(\"✅ No missing citations found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f26a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taishajoseph/miniconda3/envs/mdc-challenge-2025/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-01 10:37:08,919 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,919 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,919 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,925 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,925 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,925 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,925 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/semantic_chunking.log\n",
      "2025-08-01 10:37:08,973 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/chunking_and_embedding_services.log\n",
      "2025-08-01 10:37:08,973 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/chunking_and_embedding_services.log\n",
      "2025-08-01 10:37:08,973 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/chunking_and_embedding_services.log\n",
      "2025-08-01 10:37:08,973 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/chunking_and_embedding_services.log\n",
      "2025-08-01 10:37:08,973 - src.helpers - INFO - Logging initialized for /Users/taishajoseph/Documents/Projects/MDC-Challenge-2025/logs/chunking_and_embedding_services.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTING PATTERN MATCHING ===\n",
      "✅ No missing citations to test!\n"
     ]
    }
   ],
   "source": [
    "# Test pattern matching on missing citations\n",
    "from api.services.chunking_and_embedding_services import make_pattern\n",
    "from src.helpers import preprocess_text\n",
    "import re\n",
    "\n",
    "print(\"\\n=== TESTING PATTERN MATCHING ===\")\n",
    "\n",
    "if len(missing_citations) > 0:\n",
    "    # Take first 3 missing citations for detailed analysis\n",
    "    test_citations = list(missing_citations)[:3]\n",
    "    \n",
    "    for i, missing_citation in enumerate(test_citations, 1):\n",
    "        print(f\"\\n🔍 TESTING CITATION {i}: {missing_citation}\")\n",
    "        \n",
    "        # Find the document that contains this citation\n",
    "        citation_obj = None\n",
    "        for ce in all_citations:\n",
    "            if ce.data_citation == missing_citation:\n",
    "                citation_obj = ce\n",
    "                break\n",
    "        \n",
    "        if not citation_obj:\n",
    "            print(\"❌ Citation object not found\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"📄 Document: {citation_obj.document_id}\")\n",
    "        \n",
    "        # Get the document's chunks\n",
    "        doc_chunks = db_helper.get_chunks_by_document_id(citation_obj.document_id)\n",
    "        print(f\"📊 Document has {len(doc_chunks)} chunks\")\n",
    "        \n",
    "        # Test the pattern matching\n",
    "        pattern = make_pattern(missing_citation)\n",
    "        print(f\"🔍 Pattern: {pattern.pattern}\")\n",
    "        \n",
    "        # Check if citation appears in any chunk text (raw and preprocessed)\n",
    "        found_in_raw = 0\n",
    "        found_in_preprocessed = 0\n",
    "        found_with_pattern = 0\n",
    "        \n",
    "        for chunk in doc_chunks[:5]:  # Check first 5 chunks to avoid too much output\n",
    "            raw_text = chunk.text\n",
    "            preprocessed_text = preprocess_text(raw_text)\n",
    "            \n",
    "            # Check raw text\n",
    "            if missing_citation.lower() in raw_text.lower():\n",
    "                found_in_raw += 1\n",
    "                print(f\"  ✅ Found in raw text of chunk {chunk.chunk_id}\")\n",
    "                \n",
    "            # Check preprocessed text  \n",
    "            if missing_citation.lower() in preprocessed_text.lower():\n",
    "                found_in_preprocessed += 1\n",
    "                print(f\"  ✅ Found in preprocessed text of chunk {chunk.chunk_id}\")\n",
    "                \n",
    "            # Check pattern matching\n",
    "            if pattern.search(preprocessed_text):\n",
    "                found_with_pattern += 1\n",
    "                print(f\"  ✅ Pattern matched in chunk {chunk.chunk_id}\")\n",
    "        \n",
    "        print(f\"📊 Summary for {missing_citation}:\")\n",
    "        print(f\"  Raw text matches: {found_in_raw}\")\n",
    "        print(f\"  Preprocessed matches: {found_in_preprocessed}\")\n",
    "        print(f\"  Pattern matches: {found_with_pattern}\")\n",
    "        \n",
    "        if found_in_raw > 0 and found_with_pattern == 0:\n",
    "            print(\"⚠️  ISSUE: Citation found in raw text but pattern didn't match!\")\n",
    "        elif found_in_raw == 0:\n",
    "            print(\"⚠️  ISSUE: Citation not found in any chunk text - may be in different document!\")\n",
    "\n",
    "else:\n",
    "    print(\"✅ No missing citations to test!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67278fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANALYZING TEXT PREPROCESSING EFFECTS ===\n",
      "✅ No missing citations to analyze!\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis of text preprocessing effects\n",
    "print(\"\\n=== ANALYZING TEXT PREPROCESSING EFFECTS ===\")\n",
    "\n",
    "if len(missing_citations) > 0:\n",
    "    # Take one missing citation for detailed preprocessing analysis\n",
    "    test_citation = list(missing_citations)[0]\n",
    "    print(f\"🔍 DETAILED ANALYSIS FOR: {test_citation}\")\n",
    "    \n",
    "    # Find the citation object\n",
    "    citation_obj = None\n",
    "    for ce in all_citations:\n",
    "        if ce.data_citation == test_citation:\n",
    "            citation_obj = ce\n",
    "            break\n",
    "    \n",
    "    if citation_obj:\n",
    "        print(f\"📄 Document: {citation_obj.document_id}\")\n",
    "        \n",
    "        # Get a chunk that might contain this citation\n",
    "        doc_chunks = db_helper.get_chunks_by_document_id(citation_obj.document_id)\n",
    "        \n",
    "        # Find a chunk that contains the citation in raw text\n",
    "        target_chunk = None\n",
    "        for chunk in doc_chunks:\n",
    "            if test_citation.lower() in chunk.text.lower():\n",
    "                target_chunk = chunk\n",
    "                break\n",
    "        \n",
    "        if target_chunk:\n",
    "            print(f\"📝 Found citation in chunk: {target_chunk.chunk_id}\")\n",
    "            \n",
    "            # Show the text around the citation\n",
    "            raw_text = target_chunk.text\n",
    "            citation_pos = raw_text.lower().find(test_citation.lower())\n",
    "            \n",
    "            if citation_pos >= 0:\n",
    "                # Extract text around the citation (±100 characters)\n",
    "                start = max(0, citation_pos - 100)\n",
    "                end = min(len(raw_text), citation_pos + len(test_citation) + 100)\n",
    "                context = raw_text[start:end]\n",
    "                \n",
    "                print(f\"\\n📖 CONTEXT (raw text):\")\n",
    "                print(f\"...{context}...\")\n",
    "                \n",
    "                # Show preprocessed version\n",
    "                preprocessed_context = preprocess_text(context)\n",
    "                print(f\"\\n🔧 CONTEXT (preprocessed):\")\n",
    "                print(f\"...{preprocessed_context}...\")\n",
    "                \n",
    "                # Test different pattern approaches\n",
    "                print(f\"\\n🧪 PATTERN TESTING:\")\n",
    "                \n",
    "                # Original pattern\n",
    "                original_pattern = make_pattern(test_citation)\n",
    "                print(f\"1. Original pattern: {original_pattern.pattern}\")\n",
    "                print(f\"   Matches preprocessed: {bool(original_pattern.search(preprocessed_context))}\")\n",
    "                \n",
    "                # Simple literal search\n",
    "                print(f\"2. Simple literal search in preprocessed:\")\n",
    "                print(f\"   '{test_citation}' in preprocessed: {test_citation.lower() in preprocessed_context.lower()}\")\n",
    "                \n",
    "                # Show what make_pattern does to the citation\n",
    "                normalized_citation = re.sub(r'[^\\w\\s]', '', test_citation).lower()\n",
    "                print(f\"3. Pattern normalization:\")\n",
    "                print(f\"   Original: '{test_citation}'\")\n",
    "                print(f\"   Normalized: '{normalized_citation}'\")\n",
    "                print(f\"   Normalized in preprocessed: {normalized_citation in preprocessed_context.lower()}\")\n",
    "                \n",
    "        else:\n",
    "            print(\"❌ Citation not found in any chunk of this document\")\n",
    "            \n",
    "            # Check if citation exists in the full document text\n",
    "            document = db_helper.get_documents_by_doi([citation_obj.document_id])\n",
    "            if document:\n",
    "                doc_text = \" \".join(document[0].full_text) if isinstance(document[0].full_text, list) else document[0].full_text\n",
    "                if test_citation.lower() in doc_text.lower():\n",
    "                    print(\"⚠️  Citation exists in full document but not in any chunk!\")\n",
    "                    print(\"⚠️  This suggests chunking might have split the citation\")\n",
    "                else:\n",
    "                    print(\"❌ Citation not found in full document either\")\n",
    "\n",
    "else:\n",
    "    print(\"✅ No missing citations to analyze!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69601b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY & RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "📊 CITATION ANALYSIS RESULTS:\n",
      "  • Total citations in database: 487\n",
      "  • Citations assigned to chunks: 487\n",
      "  • Missing citations: 0\n",
      "\n",
      "📊 DATABASE CONSISTENCY:\n",
      "  • Expected chunks: 4165\n",
      "  • DuckDB chunks: 4205 (+40 stale)\n",
      "  • ChromaDB chunks: 4165 (+0)\n",
      "\n",
      "🔍 ROOT CAUSE ANALYSIS:\n",
      "✅ Missing citation count matches expectation\n",
      "🎯 CONFIRMED: Both issues stem from citation pattern matching failures\n",
      "\n",
      "💡 ISSUE #1 (485→436): 0 citations not assigned to chunks\n",
      "💡 ISSUE #2 (12 failures): Some of these missing citations are queried in retrieval\n",
      "   └─ get_query_texts() returns empty for missing citations\n",
      "   └─ Leads to 0 chunks retrieved → marked as unsuccessful\n",
      "\n",
      "🔧 RECOMMENDED FIXES:\n",
      "1. Fix make_pattern() function:\n",
      "   - Current: removes ALL punctuation, may be too aggressive\n",
      "   - Consider: preserve important separators like / - .\n",
      "   - Test: word boundaries may not work for complex identifiers\n",
      "2. Improve text preprocessing:\n",
      "   - Check if preprocess_text() is breaking citation formats\n",
      "   - Consider matching against both raw AND preprocessed text\n",
      "3. Add citation repair mechanism:\n",
      "   - Check for citations split across chunk boundaries\n",
      "   - Implement fuzzy matching for partial citations\n",
      "4. Database cleanup:\n",
      "   - Remove 40 stale chunks from DuckDB\n",
      "   - Ensure ChromaDB has complete chunk set\n",
      "\n",
      "🚀 NEXT STEPS:\n",
      "1. Run this diagnostic on a few more missing citations\n",
      "2. Test improved pattern matching functions\n",
      "3. Clean up stale database entries\n",
      "4. Re-run chunking pipeline with fixes\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary and recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 CITATION ANALYSIS RESULTS:\")\n",
    "print(f\"  • Total citations in database: {len(all_citations)}\")\n",
    "print(f\"  • Citations assigned to chunks: {len(citations_in_chunks)}\")\n",
    "print(f\"  • Missing citations: {len(missing_citations)}\")\n",
    "\n",
    "print(f\"\\n📊 DATABASE CONSISTENCY:\")\n",
    "print(f\"  • Expected chunks: {EXPECTED_CHUNKS}\")\n",
    "print(f\"  • DuckDB chunks: {actual_chunks_db} (+{actual_chunks_db - EXPECTED_CHUNKS} stale)\")\n",
    "print(f\"  • ChromaDB chunks: {total_chunks_chroma} ({total_chunks_chroma - EXPECTED_CHUNKS:+d})\")\n",
    "\n",
    "print(f\"\\n🔍 ROOT CAUSE ANALYSIS:\")\n",
    "\n",
    "if len(missing_citations) == (len(all_citations) - len(citations_in_chunks)):\n",
    "    print(\"✅ Missing citation count matches expectation\")\n",
    "    print(\"🎯 CONFIRMED: Both issues stem from citation pattern matching failures\")\n",
    "    \n",
    "    print(f\"\\n💡 ISSUE #1 (485→436): {len(missing_citations)} citations not assigned to chunks\")\n",
    "    print(\"💡 ISSUE #2 (12 failures): Some of these missing citations are queried in retrieval\")\n",
    "    print(\"   └─ get_query_texts() returns empty for missing citations\")\n",
    "    print(\"   └─ Leads to 0 chunks retrieved → marked as unsuccessful\")\n",
    "    \n",
    "    print(f\"\\n🔧 RECOMMENDED FIXES:\")\n",
    "    print(\"1. Fix make_pattern() function:\")\n",
    "    print(\"   - Current: removes ALL punctuation, may be too aggressive\")\n",
    "    print(\"   - Consider: preserve important separators like / - .\")\n",
    "    print(\"   - Test: word boundaries may not work for complex identifiers\")\n",
    "    \n",
    "    print(\"2. Improve text preprocessing:\")\n",
    "    print(\"   - Check if preprocess_text() is breaking citation formats\")\n",
    "    print(\"   - Consider matching against both raw AND preprocessed text\")\n",
    "    \n",
    "    print(\"3. Add citation repair mechanism:\")\n",
    "    print(\"   - Check for citations split across chunk boundaries\")\n",
    "    print(\"   - Implement fuzzy matching for partial citations\")\n",
    "    \n",
    "    print(\"4. Database cleanup:\")\n",
    "    print(f\"   - Remove {actual_chunks_db - EXPECTED_CHUNKS} stale chunks from DuckDB\")\n",
    "    print(\"   - Ensure ChromaDB has complete chunk set\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  Citation count mismatch detected - need further investigation\")\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS:\")\n",
    "print(\"1. Run this diagnostic on a few more missing citations\")\n",
    "print(\"2. Test improved pattern matching functions\")\n",
    "print(\"3. Clean up stale database entries\")\n",
    "print(\"4. Re-run chunking pipeline with fixes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1572235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChunkMetadata(chunk_id='10.1136_jitc-2021-003114_5', previous_chunk_id='10.1136_jitc-2021-003114_4', next_chunk_id='10.1136_jitc-2021-003114_6', token_count=608, citation_entities=[CitationEntity(data_citation='CVCL_0395', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_0530', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_0627', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_1916', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_1917', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_1918', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_1919', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_2213', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_2235', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_3967', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_6245', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None), CitationEntity(data_citation='CVCL_7151', document_id='10.1136_jitc-2021-003114', pages=[2], evidence=None)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = db_helper.get_chunks_by_chunk_ids([\"10.1136_jitc-2021-003114_5\"])\n",
    "chunk[0].chunk_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447a6263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Verification Results:\n",
      "  • Citations attempted in retrieval: 487\n",
      "  • Failed retrievals: 0\n",
      "  • Missing citations (never reached retrieval): 0\n",
      "  • Overlap between failed and missing: 0\n",
      "✅ CONFIRMED: These are two separate issues\n",
      "📊 Total problems: 0 + 0 = 0\n"
     ]
    }
   ],
   "source": [
    "# Verify separation of issues\n",
    "import json\n",
    "\n",
    "# Load retrieval results\n",
    "retrieval_results_path = project_root / \"reports\" / \"retrieval\" / \"retrieval_results.json\"\n",
    "with open(retrieval_results_path, 'r') as f:\n",
    "    retrieval_data = json.load(f)\n",
    "\n",
    "# Find failed retrievals\n",
    "chunk_ids_map = retrieval_data.get('chunk_ids', {})\n",
    "failed_retrievals = [cid for cid, chunks in chunk_ids_map.items() if not chunks or len(chunks) == 0]\n",
    "\n",
    "print(f\"📊 Verification Results:\")\n",
    "print(f\"  • Citations attempted in retrieval: {len(chunk_ids_map)}\")\n",
    "print(f\"  • Failed retrievals: {len(failed_retrievals)}\")\n",
    "print(f\"  • Missing citations (never reached retrieval): {len(missing_citations)}\")\n",
    "\n",
    "# Check overlap\n",
    "overlap = set(failed_retrievals) & missing_citations\n",
    "print(f\"  • Overlap between failed and missing: {len(overlap)}\")\n",
    "\n",
    "if len(overlap) == 0:\n",
    "    print(\"✅ CONFIRMED: These are two separate issues\")\n",
    "    print(f\"📊 Total problems: {len(missing_citations)} + {len(failed_retrievals)} = {len(missing_citations) + len(failed_retrievals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3403c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:37:09,079 - src.helpers - INFO - Database connection closed\n",
      "2025-08-01 10:37:09,079 - src.helpers - INFO - Database connection closed\n",
      "2025-08-01 10:37:09,079 - src.helpers - INFO - Database connection closed\n",
      "2025-08-01 10:37:09,079 - src.helpers - INFO - Database connection closed\n",
      "2025-08-01 10:37:09,079 - src.helpers - INFO - Database connection closed\n"
     ]
    }
   ],
   "source": [
    "db_helper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf7403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_ids_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bb52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min chunks across all citations: 3\n",
      "Max chunks across all citations: 6\n"
     ]
    }
   ],
   "source": [
    "# get list of n chunks per citation in chunk_ids_map\n",
    "n_chunks_list = [len(chunks) for chunks in chunk_ids_map.values()]\n",
    "print(f\"Min chunks across all citations: {min(n_chunks_list)}\")\n",
    "print(f\"Max chunks across all citations: {max(n_chunks_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdc-challenge-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
